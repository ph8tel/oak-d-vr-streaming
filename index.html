<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8" />
  <title>VR Telepresence</title>
  <style>
    body {
      background: #000;
      color: #fff;
      font-family: sans-serif;
    }
    #enter-vr {
      position: absolute;
      top: 20px;
      left: 20px;
      padding: 10px 20px;
      background: #0a84ff;
      border: none;
      color: #fff;
      font-size: 16px;
      cursor: pointer;
    }
  </style>
</head>
<body>
  <button id="enter-vr">Enter VR</button>

  <!-- Hidden video elements just as texture sources -->
  <video id="leftVideo" autoplay playsinline muted style="display:none"></video>
  <video id="rightVideo" autoplay playsinline muted style="display:none"></video>

  <canvas id="glcanvas"></canvas>

  <script>
    let pc;
    let leftVideo = document.getElementById("leftVideo");
    let rightVideo = document.getElementById("rightVideo");

    let xrSession = null;
    let gl = null;
    let xrRefSpace = null;
    let xrLayer = null;

    let leftTexture = null;
    let rightTexture = null;
    let program = null;
    let positionBuffer = null;
    let texcoordBuffer = null;

    let calib = null

    async function loadCalibration() {
      const res = await fetch("/calibration");
      calib = await res.json();
    }

    function projectionFromIntrinsics(K, width, height, near, far) {
      const fx = K[0][0];
      const fy = K[1][1];
      const cx = K[0][2];
      const cy = K[1][2];
    
      const proj = new Float32Array(16);
    
      proj[0]  =  2 * fx / width;
      proj[5]  =  2 * fy / height;
      proj[8]  =  1 - (2 * cx / width);
      proj[9]  =  (2 * cy / height) - 1;
      proj[10] = -(far + near) / (far - near);
      proj[11] = -1;
      proj[14] = -(2 * far * near) / (far - near);
    
      return proj;
    }

    async function startWebRTC() {
      pc = new RTCPeerConnection();

      let videoCount = 0;
      pc.ontrack = (event) => {
        if (event.track.kind !== "video") return;

        const stream = new MediaStream([event.track]);
        let targetVideo = null;

        // Use transceiver mid to deterministically map tracks
        if (event.transceiver && event.transceiver.mid !== null) {
          targetVideo = event.transceiver.mid === "0" ? leftVideo : rightVideo;
        } else {
          targetVideo = videoCount === 0 ? leftVideo : rightVideo;
        }
        targetVideo.srcObject = stream;

        targetVideo.onloadedmetadata = () => {
          targetVideo.play().catch(() => {});
        };

        videoCount++;
      };

      // Two recvonly video transceivers
      pc.addTransceiver("video", { direction: "recvonly" });
      pc.addTransceiver("video", { direction: "recvonly" });

      const offer = await pc.createOffer();
      await pc.setLocalDescription(offer);

      const response = await fetch("/offer", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({
          sdp: offer.sdp,
          type: offer.type
        })
      });

      const answer = await response.json();
      await pc.setRemoteDescription(answer);
    }

    function createShader(gl, type, source) {
      const shader = gl.createShader(type);
      gl.shaderSource(shader, source);
      gl.compileShader(shader);
      return shader;
    }

    function initGLResources() {
      const canvas = document.getElementById("glcanvas");
      gl = canvas.getContext("webgl", { xrCompatible: true });

      const vsSource = `
        attribute vec2 a_position;
        attribute vec2 a_texcoord;

        uniform mat4 uProjection;
        uniform mat4 uView;

        varying vec2 v_texcoord;
        void main() {
          v_texcoord = a_texcoord;
          gl_Position = uProjection * uView * vec(a_position, 0.0, 1.0);
        }
      `;

      const fsSource = `
        precision mediump float;
        varying vec2 v_texcoord;
        uniform sampler2D u_texture;
        void main() {
          gl_FragColor = texture2D(u_texture, v_texcoord);
        }
      `;

      const vs = createShader(gl, gl.VERTEX_SHADER, vsSource);
      const fs = createShader(gl, gl.FRAGMENT_SHADER, fsSource);

      program = gl.createProgram();
      const uProjectionLoc = gl.getUniformLocation(program, "uProjection");
      const uViewLoc = gl.getUniformLocation(program, "uView");
      gl.attachShader(program, vs);
      gl.attachShader(program, fs);
      gl.linkProgram(program);

      positionBuffer = gl.createBuffer();
      gl.bindBuffer(gl.ARRAY_BUFFER, positionBuffer);
      // Fullscreen quad
      gl.bufferData(gl.ARRAY_BUFFER, new Float32Array([
        -1, -1,
         1, -1,
        -1,  1,
        -1,  1,
         1, -1,
         1,  1,
      ]), gl.STATIC_DRAW);

      texcoordBuffer = gl.createBuffer();
      gl.bindBuffer(gl.ARRAY_BUFFER, texcoordBuffer);
      gl.bufferData(gl.ARRAY_BUFFER, new Float32Array([
        0, 1,
        1, 1,
        0, 0,
        0, 0,
        1, 1,
        1, 0,
      ]), gl.STATIC_DRAW);

      leftTexture = gl.createTexture();
      gl.bindTexture(gl.TEXTURE_2D, leftTexture);
      gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.LINEAR);
      gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.LINEAR);
      gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
      gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);

      rightTexture = gl.createTexture();
      gl.bindTexture(gl.TEXTURE_2D, rightTexture);
      gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.LINEAR);
      gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.LINEAR);
      gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
      gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);
    }

    async function startXR() {
      if (!navigator.xr) {
        alert("WebXR not supported");
        return;
      }

      await startWebRTC(); // ensure streams are flowing
      await loadCalibration(); // get calibration data from camera

      if (!gl) {
        initGLResources();
      }
      const width = 1280;
      const height = 800;
      const near = 0.01;
      const far = 1000.0;
      
      const projLeft  = projectionFromIntrinsics(calib.k_left,  width, height, near, far);
      const projRight = projectionFromIntrinsics(calib.k_right, width, height, near, far);
      xrSession = await navigator.xr.requestSession("immersive-vr", {
        requiredFeatures: ["local-floor"]
      });

      await gl.makeXRCompatible();
      xrLayer = new XRWebGLLayer(xrSession, gl);
      xrSession.updateRenderState({ baseLayer: xrLayer });

      xrRefSpace = await xrSession.requestReferenceSpace("local-floor");
      xrSession.requestAnimationFrame(onXRFrame);
    }

    function updateTextureFromVideo(texture, video) {
      if (video.readyState < 2) return; // HAVE_CURRENT_DATA
      gl.bindTexture(gl.TEXTURE_2D, texture);
      gl.texImage2D(
        gl.TEXTURE_2D,
        0,
        gl.RGB,
        gl.RGB,
        gl.UNSIGNED_BYTE,
        video
      );
    }

    function onXRFrame(time, frame) {
  const session = frame.session;
  const pose = frame.getViewerPose(xrRefSpace);
  if (!pose) {
    session.requestAnimationFrame(onXRFrame);
    return;
  }

  const baseLayer = session.renderState.baseLayer;
  gl.bindFramebuffer(gl.FRAMEBUFFER, baseLayer.framebuffer);
  gl.clearColor(0, 0, 0, 1);
  gl.clear(gl.COLOR_BUFFER_BIT);

  gl.useProgram(program);

  const views = pose.views;

  for (let i = 0; i < views.length; i++) {
    const view = views[i];
    const viewport = baseLayer.getViewport(view);
    gl.viewport(viewport.x, viewport.y, viewport.width, viewport.height);

    // --- NEW: projection + view override ---
    const proj = (view.eye === "left") ? projLeft : projRight;

    const viewMatrix = new Float32Array(view.transform.inverse.matrix);
    const baseline = calib.baseline_m;
    viewMatrix[12] = (view.eye === "left") ? -baseline / 2 : baseline / 2;

    gl.uniformMatrix4fv(uProjectionLoc, false, proj);
    gl.uniformMatrix4fv(uViewLoc, false, viewMatrix);
    // ---------------------------------------

    if (i === 0) {
      updateTextureFromVideo(leftTexture, leftVideo);
      gl.bindTexture(gl.TEXTURE_2D, leftTexture);
    } else {
      updateTextureFromVideo(rightTexture, rightVideo);
      gl.bindTexture(gl.TEXTURE_2D, rightTexture);
    }

    gl.uniform1i(samplerLoc, 0);
    gl.drawArrays(gl.TRIANGLES, 0, 6);
  }

  session.requestAnimationFrame(onXRFrame);
}

    document.getElementById("enter-vr").addEventListener("click", () => {
      startXR();
    });
  </script>
</body>

</html>

